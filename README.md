# 抽出型文書要約
## 手続き
1. クリーニング(文区切り)
1. 文章の単語分割(形態素解析)
1. 単語の正規化(絵文字/記号などの削除，同じ意味を持つ単語の統一)
1. ストップワードの除去(名詞/形容詞/副詞/動詞のみの利用，辞書による除去)
1. 文書のベクトル表現(TF-IDF)*
1. 要約モデルの適用(LexRank)

## 使用技術/手法
coming soon

## 参考文献
文章要約の全体なまとめ
- [文書要約の歴史](https://qiita.com/siida36/items/4c0dbaa07c456a9fadd0)
テキストからセンテンス分割
- [ja_sentence_segmenter](https://github.com/wwwcojp/ja_sentence_segmenter)
前処理 (クリーニング処理)
- 自然言語（前）処理
- 自然言語処理における前処理の種類とその威力 ← 順を追って説明してくれる
- 自然言語処理の前処理について ← 絵文字の削除など
- データの前処理 ← ベースはこれを参考にした
形態素解析 (文章の単語分割)
- 品詞推定(隠れマルコフ，ビタビアルゴリズム)
- 【技術解説】形態素解析とは？MeCabインストール手順からPythonでの実行例まで ← MeCabによる形態素解析
- Python: LexRankで日本語の記事を要約する ← janomeによる形態素解析
単語の正規化
- 自然言語処理における前処理の種類とその威力
- 自然言語処理の前処理とMeCab(形態素解析エンジン)について
ストップワードの除去
- 日本語ストップワードの考察【品詞別】
単語/文の重要度 (単語/文の分散表現)
- TF-IDF(ある文における重要単語の抽出)
- Word2Vecとは
文章要約モデル (抽出型要約)
- LexRank
- LexRankによる代表文抽出 ← 考え方がわかりやすい
- A3RTとユーザーローカルの文章の自動要約を試してみた ← Doc2vecのAPI

# extractive-summarization
